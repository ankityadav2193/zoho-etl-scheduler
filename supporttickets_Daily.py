{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "423c1129-3020-43b2-9c1f-0281c9a7996b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access Token: 1000.63e30098f8cd0701ee36d2b8e7d37173.91687dcd054942d3551a9366cd8eedcc\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "# --- Replace with your actual values ---\n",
    "ACCOUNTS_HOST = \"https://accounts.zoho.com\"  # or .eu / .in depending on your region\n",
    "CLIENT_ID = \"1000.VZGLA3ZLMB3GT2POZF8BIPMXDTKRLQ\"\n",
    "CLIENT_SECRET = \"26189683ff2d8cc1c8b2c86ac7c118afdfb4201a7a\"\n",
    "REDIRECT_URI = \"https://www.zoho.com\"\n",
    "\n",
    "# Path to save tokens\n",
    "TOKEN_FILE = \"zoho_tokens.json\"\n",
    "\n",
    "\n",
    "def save_tokens(tokens):\n",
    "    \"\"\"Save tokens to file\"\"\"\n",
    "    with open(TOKEN_FILE, \"w\") as f:\n",
    "        json.dump(tokens, f)\n",
    "\n",
    "\n",
    "def load_tokens():\n",
    "    \"\"\"Load tokens from file\"\"\"\n",
    "    if os.path.exists(TOKEN_FILE):\n",
    "        with open(TOKEN_FILE, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "\n",
    "def get_tokens_with_auth_code(auth_code):\n",
    "    \"\"\"Exchange AUTH_CODE for access + refresh tokens\"\"\"\n",
    "    data = {\n",
    "        \"grant_type\": \"authorization_code\",\n",
    "        \"client_id\": CLIENT_ID,\n",
    "        \"client_secret\": CLIENT_SECRET,\n",
    "        \"code\": auth_code,\n",
    "        \"redirect_uri\": REDIRECT_URI,\n",
    "    }\n",
    "    r = requests.post(f\"{ACCOUNTS_HOST}/oauth/v2/token\", data=data)\n",
    "    tokens = r.json()\n",
    "\n",
    "    if \"error\" in tokens:\n",
    "        raise Exception(f\"Failed to get tokens with auth code: {tokens}\")\n",
    "\n",
    "    save_tokens(tokens)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def refresh_access_token():\n",
    "    \"\"\"Use refresh_token to get a new access_token\"\"\"\n",
    "    tokens = load_tokens()\n",
    "    refresh_token = tokens.get(\"refresh_token\")\n",
    "\n",
    "    if not refresh_token:\n",
    "        raise Exception(\"No refresh_token found! Run with AUTH_CODE first.\")\n",
    "\n",
    "    data = {\n",
    "        \"grant_type\": \"refresh_token\",\n",
    "        \"client_id\": CLIENT_ID,\n",
    "        \"client_secret\": CLIENT_SECRET,\n",
    "        \"refresh_token\": refresh_token,\n",
    "    }\n",
    "\n",
    "    r = requests.post(f\"{ACCOUNTS_HOST}/oauth/v2/token\", data=data)\n",
    "    new_tokens = r.json()\n",
    "\n",
    "    if \"error\" in new_tokens:\n",
    "        raise Exception(f\"Failed to refresh access token: {new_tokens}\")\n",
    "\n",
    "    # Keep old refresh_token if not returned again\n",
    "    if \"refresh_token\" not in new_tokens:\n",
    "        new_tokens[\"refresh_token\"] = refresh_token\n",
    "\n",
    "    tokens.update(new_tokens)\n",
    "    save_tokens(tokens)\n",
    "\n",
    "    return new_tokens.get(\"access_token\")\n",
    "\n",
    "\n",
    "def get_access_token():\n",
    "    \"\"\"Main function: auto-detect first run vs refresh\"\"\"\n",
    "    tokens = load_tokens()\n",
    "\n",
    "    if not tokens.get(\"refresh_token\"):\n",
    "        # First time only: ask user for AUTH_CODE\n",
    "        auth_code = input(\"Enter your Zoho AUTH_CODE (from console): \").strip()\n",
    "        tokens = get_tokens_with_auth_code(auth_code)\n",
    "        print(\"✅ Refresh token saved for future use.\")\n",
    "\n",
    "    return refresh_access_token()\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Usage Example\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    access_token = get_access_token()\n",
    "    print(\"Access Token:\", access_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a7ae72a9-9ccf-4bd4-b119-92ee725a9d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 4 contacts starting from 1\n",
      "Error: 204 - \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "ACCESS_TOKEN = get_access_token() \n",
    "#ACCESS_TOKEN = new_tokens.get(\"access_token\")\n",
    "ORG_ID = \"852203610\"\n",
    "\n",
    "#BASE_URL = \"https://desk.zoho.com/api/v1/tickets\"\n",
    "BASE_URL = \"https://desk.zoho.com/api/v1/departments\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Zoho-oauthtoken {ACCESS_TOKEN}\",\n",
    "    \"orgId\": ORG_ID\n",
    "}\n",
    "\n",
    "limit = 100  # Zoho Desk max per request\n",
    "start = 1\n",
    "all_contacts_summary = []\n",
    "all_contacts_details = []\n",
    "\n",
    "# Step 1: Loop to get all contacts\n",
    "while True:\n",
    "    params = {\n",
    "        \"limit\": limit,\n",
    "        \"from\": start\n",
    "    }\n",
    "    resp = requests.get(BASE_URL, headers=headers, params=params)\n",
    "    \n",
    "    if resp.status_code != 200:\n",
    "        print(f\"Error: {resp.status_code} - {resp.text}\")\n",
    "        break\n",
    "\n",
    "    data = resp.json().get(\"data\", [])\n",
    "    if not data:\n",
    "        break  # No more contacts\n",
    "\n",
    "    all_contacts_summary.extend(data)\n",
    "    print(f\"Fetched {len(data)} contacts starting from {start}\")\n",
    "\n",
    "    start += limit  # Move to next page\n",
    "\n",
    "# Step 2: Get full details for each contact\n",
    "for contact in all_contacts_summary:\n",
    "    contact_id = contact[\"id\"]\n",
    "    detail_url = f\"{BASE_URL}/{contact_id}\"\n",
    "    detail_resp = requests.get(detail_url, headers=headers)\n",
    "    \n",
    "    if detail_resp.status_code != 200:\n",
    "        print(f\"Error fetching contact {contact_id}: {detail_resp.text}\")\n",
    "        continue\n",
    "\n",
    "    detail_data = detail_resp.json()\n",
    "    all_contacts_details.append(detail_data)\n",
    "\n",
    "# Step 3: Flatten nested JSON so fields become columns\n",
    "df = pd.json_normalize(all_contacts_details, sep=\".\")\n",
    "\n",
    "# Step 4: Save to CSV and Excel\n",
    "#df.to_csv(\"zoho_departments_full.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "#df.to_excel(\"zoho_departments_full.xlsx\", index=False)\n",
    "\n",
    "#print(f\"✅ Saved {len(all_contacts_details)} departments with full details to CSV and Excel.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6bf05035-5285-49a5-91d6-07be595b85f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python in c:\\users\\ankityadav\\anaconda3\\lib\\site-packages (9.4.0)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\ankityadav\\anaconda3\\lib\\site-packages (2.0.34)\n",
      "Requirement already satisfied: pymysql in c:\\users\\ankityadav\\anaconda3\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\ankityadav\\anaconda3\\lib\\site-packages (from sqlalchemy) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ankityadav\\anaconda3\\lib\\site-packages (from sqlalchemy) (3.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mysql-connector-python sqlalchemy pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0a77d796-94f4-4e43-a256-f28c4ec671c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# MySQL connection details\n",
    "MYSQL_USER = 'integrationuser'\n",
    "MYSQL_PASSWORD = 'g1MBcJcn9bTkKgmmTzPGnWMPR499X76S66f52U9g'\n",
    "MYSQL_HOST = 'data-integration-aurora.cz4wwgmu4f45.us-east-2.rds.amazonaws.com'         # or your DB host\n",
    "MYSQL_PORT = 3306\n",
    "MYSQL_DB = 'supporttickets'\n",
    "TABLE_NAME = 'department'\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine(f'mysql+pymysql://{MYSQL_USER}:{MYSQL_PASSWORD}@{MYSQL_HOST}:{MYSQL_PORT}/{MYSQL_DB}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c9313859-4807-4280-9e30-94f80c8f034d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "# Convert list columns to JSON string\n",
    "df['associatedAgentIds'] = df['associatedAgentIds'].apply(lambda x: json.dumps(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Now write to MySQL\n",
    "df.to_sql(name=TABLE_NAME, con=engine, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b441433a-b642-4408-91aa-bdcd96ac15b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 204 - \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "ACCESS_TOKEN = get_access_token()  # Use your token logic\n",
    "ORG_ID = \"852203610\"\n",
    "BASE_URL = \"https://desk.zoho.com/api/v1/contacts\"\n",
    "headers = {\"Authorization\": f\"Zoho-oauthtoken {ACCESS_TOKEN}\", \"orgId\": ORG_ID}\n",
    "\n",
    "limit = 100\n",
    "start = 1\n",
    "all_contacts_summary = []\n",
    "\n",
    "# Step 1: Pagination to get summary\n",
    "while True:\n",
    "    params = {\"limit\": limit, \"from\": start}\n",
    "    resp = requests.get(BASE_URL, headers=headers, params=params)\n",
    "    if resp.status_code != 200:\n",
    "        print(f\"Error: {resp.status_code} - {resp.text}\")\n",
    "        break\n",
    "    data = resp.json().get(\"data\", [])\n",
    "    if not data:\n",
    "        break\n",
    "    all_contacts_summary.extend(data)\n",
    "    start += limit\n",
    "\n",
    "# Step 2: Function to fetch contact details\n",
    "def fetch_contact_detail(contact):\n",
    "    contact_id = contact[\"id\"]\n",
    "    detail_url = f\"{BASE_URL}/{contact_id}\"\n",
    "    try:\n",
    "        r = requests.get(detail_url, headers=headers)\n",
    "        if r.status_code == 200:\n",
    "            return r.json()\n",
    "        else:\n",
    "            print(f\"Error {r.status_code} fetching {contact_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception fetching {contact_id}: {e}\")\n",
    "    return None\n",
    "\n",
    "# Step 3: Parallel processing with ThreadPoolExecutor\n",
    "all_contacts_details = []\n",
    "with ThreadPoolExecutor(max_workers=30) as executor:  # adjust workers as needed\n",
    "    futures = [executor.submit(fetch_contact_detail, c) for c in all_contacts_summary]\n",
    "    for future in as_completed(futures):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            all_contacts_details.append(result)\n",
    "\n",
    "# Step 4: Flatten JSON and save\n",
    "df = pd.json_normalize(all_contacts_details, sep=\".\")\n",
    "#df.to_excel(\"zoho_contacts_full.xlsx\", index=False)\n",
    "#print(f\"✅ Saved {len(all_contacts_details)} contacts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cb0bd506-484c-408d-9466-8faac89bd3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# MySQL connection details\n",
    "MYSQL_USER = 'integrationuser'\n",
    "MYSQL_PASSWORD = 'g1MBcJcn9bTkKgmmTzPGnWMPR499X76S66f52U9g'\n",
    "MYSQL_HOST = 'data-integration-aurora.cz4wwgmu4f45.us-east-2.rds.amazonaws.com'         # or your DB host\n",
    "MYSQL_PORT = 3306\n",
    "MYSQL_DB = 'supporttickets'\n",
    "TABLE_NAME = 'contacts'\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine(f'mysql+pymysql://{MYSQL_USER}:{MYSQL_PASSWORD}@{MYSQL_HOST}:{MYSQL_PORT}/{MYSQL_DB}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3491e685-089a-41b9-9397-c7208d11e749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now write to MySQL\n",
    "df.to_sql(name=TABLE_NAME, con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "580a38af-2505-49c4-96e3-2aa8c95009e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 6 contacts starting from 1\n",
      "Error: 204 - \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "ACCESS_TOKEN = get_access_token()  # Use your token logic\n",
    "ORG_ID = \"852203610\"\n",
    "\n",
    "#BASE_URL = \"https://desk.zoho.com/api/v1/tickets\"\n",
    "BASE_URL = \"https://desk.zoho.com/api/v1/agents\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Zoho-oauthtoken {ACCESS_TOKEN}\",\n",
    "    \"orgId\": ORG_ID\n",
    "}\n",
    "\n",
    "limit = 100  # Zoho Desk max per request\n",
    "start = 1\n",
    "all_contacts_summary = []\n",
    "all_contacts_details = []\n",
    "\n",
    "# Step 1: Loop to get all contacts\n",
    "while True:\n",
    "    params = {\n",
    "        \"limit\": limit,\n",
    "        \"from\": start\n",
    "    }\n",
    "    resp = requests.get(BASE_URL, headers=headers, params=params)\n",
    "    \n",
    "    if resp.status_code != 200:\n",
    "        print(f\"Error: {resp.status_code} - {resp.text}\")\n",
    "        break\n",
    "\n",
    "    data = resp.json().get(\"data\", [])\n",
    "    if not data:\n",
    "        break  # No more contacts\n",
    "\n",
    "    all_contacts_summary.extend(data)\n",
    "    print(f\"Fetched {len(data)} contacts starting from {start}\")\n",
    "\n",
    "    start += limit  # Move to next page\n",
    "\n",
    "# Step 2: Get full details for each contact\n",
    "for contact in all_contacts_summary:\n",
    "    contact_id = contact[\"id\"]\n",
    "    detail_url = f\"{BASE_URL}/{contact_id}\"\n",
    "    detail_resp = requests.get(detail_url, headers=headers)\n",
    "    \n",
    "    if detail_resp.status_code != 200:\n",
    "        print(f\"Error fetching contact {contact_id}: {detail_resp.text}\")\n",
    "        continue\n",
    "\n",
    "    detail_data = detail_resp.json()\n",
    "    all_contacts_details.append(detail_data)\n",
    "\n",
    "# Step 3: Flatten nested JSON so fields become columns\n",
    "df = pd.json_normalize(all_contacts_details, sep=\".\")\n",
    "\n",
    "# Step 4: Save to CSV and Excel\n",
    "#df.to_csv(\"zoho_departments_full.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "#df.to_excel(\"zoho_agents_full.xlsx\", index=False)\n",
    "\n",
    "#print(f\"✅ Saved {len(all_contacts_details)} departments with full details to CSV and Excel.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0dd8b9a2-0cb8-4b22-ac3e-1da5f50161c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# MySQL connection details\n",
    "MYSQL_USER = 'integrationuser'\n",
    "MYSQL_PASSWORD = 'g1MBcJcn9bTkKgmmTzPGnWMPR499X76S66f52U9g'\n",
    "MYSQL_HOST = 'data-integration-aurora.cz4wwgmu4f45.us-east-2.rds.amazonaws.com'         # or your DB host\n",
    "MYSQL_PORT = 3306\n",
    "MYSQL_DB = 'supporttickets'\n",
    "TABLE_NAME = 'agents'\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine(f'mysql+pymysql://{MYSQL_USER}:{MYSQL_PASSWORD}@{MYSQL_HOST}:{MYSQL_PORT}/{MYSQL_DB}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8908d7f0-f296-431c-88aa-e7c419429e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "list_cols = ['associatedDepartmentIds', 'associatedChatDepartmentIds', 'channelExpert']\n",
    "\n",
    "for col in list_cols:\n",
    "    df[col] = df[col].apply(lambda x: json.dumps(x) if isinstance(x, list) else x)\n",
    "\n",
    "df = df.replace({'': None})\n",
    "\n",
    "# Now write to MySQL\n",
    "df.to_sql(name=TABLE_NAME, con=engine, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4b2659ec-f8e1-4bb9-a244-87519130a654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 204 - \n",
      "Error 429 fetching 980891000000300702\n",
      "Error 429 fetching 980891000004609001\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "ACCESS_TOKEN = get_access_token()  # Use your token logic\n",
    "ORG_ID = \"852203610\"\n",
    "BASE_URL = \"https://desk.zoho.com/api/v1/products\"\n",
    "headers = {\"Authorization\": f\"Zoho-oauthtoken {ACCESS_TOKEN}\", \"orgId\": ORG_ID}\n",
    "\n",
    "limit = 100\n",
    "start = 1\n",
    "all_contacts_summary = []\n",
    "\n",
    "# Step 1: Pagination to get summary\n",
    "while True:\n",
    "    params = {\"limit\": limit, \"from\": start}\n",
    "    resp = requests.get(BASE_URL, headers=headers, params=params)\n",
    "    if resp.status_code != 200:\n",
    "        print(f\"Error: {resp.status_code} - {resp.text}\")\n",
    "        break\n",
    "    data = resp.json().get(\"data\", [])\n",
    "    if not data:\n",
    "        break\n",
    "    all_contacts_summary.extend(data)\n",
    "    start += limit\n",
    "\n",
    "# Step 2: Function to fetch contact details\n",
    "def fetch_contact_detail(contact):\n",
    "    contact_id = contact[\"id\"]\n",
    "    detail_url = f\"{BASE_URL}/{contact_id}\"\n",
    "    try:\n",
    "        r = requests.get(detail_url, headers=headers)\n",
    "        if r.status_code == 200:\n",
    "            return r.json()\n",
    "        else:\n",
    "            print(f\"Error {r.status_code} fetching {contact_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception fetching {contact_id}: {e}\")\n",
    "    return None\n",
    "\n",
    "# Step 3: Parallel processing with ThreadPoolExecutor\n",
    "all_contacts_details = []\n",
    "with ThreadPoolExecutor(max_workers=30) as executor:  # adjust workers as needed\n",
    "    futures = [executor.submit(fetch_contact_detail, c) for c in all_contacts_summary]\n",
    "    for future in as_completed(futures):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            all_contacts_details.append(result)\n",
    "\n",
    "# Step 4: Flatten JSON and save\n",
    "df = pd.json_normalize(all_contacts_details, sep=\".\")\n",
    "#df.to_excel(\"zoho_contacts_full.xlsx\", index=False)\n",
    "#print(f\"✅ Saved {len(all_contacts_details)} contacts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8332ba81-9cab-4eff-a990-4f7318dc7744",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# MySQL connection details\n",
    "MYSQL_USER = 'integrationuser'\n",
    "MYSQL_PASSWORD = 'g1MBcJcn9bTkKgmmTzPGnWMPR499X76S66f52U9g'\n",
    "MYSQL_HOST = 'data-integration-aurora.cz4wwgmu4f45.us-east-2.rds.amazonaws.com'         # or your DB host\n",
    "MYSQL_PORT = 3306\n",
    "MYSQL_DB = 'supporttickets'\n",
    "TABLE_NAME = 'products'\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine(f'mysql+pymysql://{MYSQL_USER}:{MYSQL_PASSWORD}@{MYSQL_HOST}:{MYSQL_PORT}/{MYSQL_DB}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b6928348-246d-4994-bf9e-8bab4b84710d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['departmentIds'] = df['departmentIds'].apply(lambda x: ','.join(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Now write to MySQL\n",
    "df.to_sql(name=TABLE_NAME, con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "099044a1-4851-4ba5-8a4f-75631eb60701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 204 - \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "ACCESS_TOKEN = get_access_token()  # Use your token logic\n",
    "ORG_ID = \"852203610\"\n",
    "BASE_URL = \"https://desk.zoho.com/api/v1/tickets\"\n",
    "headers = {\"Authorization\": f\"Zoho-oauthtoken {ACCESS_TOKEN}\", \"orgId\": ORG_ID}\n",
    "\n",
    "limit = 100\n",
    "start = 1\n",
    "all_contacts_summary = []\n",
    "\n",
    "# Step 1: Pagination to get summary\n",
    "while True:\n",
    "    params = {\"limit\": limit, \"from\": start}\n",
    "    resp = requests.get(BASE_URL, headers=headers, params=params)\n",
    "    if resp.status_code != 200:\n",
    "        print(f\"Error: {resp.status_code} - {resp.text}\")\n",
    "        break\n",
    "    data = resp.json().get(\"data\", [])\n",
    "    if not data:\n",
    "        break\n",
    "    all_contacts_summary.extend(data)\n",
    "    start += limit\n",
    "\n",
    "# Step 2: Function to fetch contact details\n",
    "def fetch_contact_detail(contact):\n",
    "    contact_id = contact[\"id\"]\n",
    "    detail_url = f\"{BASE_URL}/{contact_id}\"\n",
    "    try:\n",
    "        r = requests.get(detail_url, headers=headers)\n",
    "        if r.status_code == 200:\n",
    "            return r.json()\n",
    "        else:\n",
    "            print(f\"Error {r.status_code} fetching {contact_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception fetching {contact_id}: {e}\")\n",
    "    return None\n",
    "\n",
    "# Step 3: Parallel processing with ThreadPoolExecutor\n",
    "all_contacts_details = []\n",
    "with ThreadPoolExecutor(max_workers=30) as executor:  # adjust workers as needed\n",
    "    futures = [executor.submit(fetch_contact_detail, c) for c in all_contacts_summary]\n",
    "    for future in as_completed(futures):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            all_contacts_details.append(result)\n",
    "\n",
    "# Step 4: Flatten JSON and save\n",
    "df = pd.json_normalize(all_contacts_details, sep=\".\")\n",
    "#df.to_excel(\"zoho_contacts_full.xlsx\", index=False)\n",
    "#print(f\"✅ Saved {len(all_contacts_details)} contacts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7836d68a-ecd2-4d7c-8273-e907a0a57d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# MySQL connection details\n",
    "MYSQL_USER = 'integrationuser'\n",
    "MYSQL_PASSWORD = 'g1MBcJcn9bTkKgmmTzPGnWMPR499X76S66f52U9g'\n",
    "MYSQL_HOST = 'data-integration-aurora.cz4wwgmu4f45.us-east-2.rds.amazonaws.com'         # or your DB host\n",
    "MYSQL_PORT = 3306\n",
    "MYSQL_DB = 'supporttickets'\n",
    "TABLE_NAME = 'tickets'\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine(f'mysql+pymysql://{MYSQL_USER}:{MYSQL_PASSWORD}@{MYSQL_HOST}:{MYSQL_PORT}/{MYSQL_DB}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e72c5181-2167-4b87-9a21-2643cc107db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "703"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "list_columns = ['sharedDepartments', 'entitySkills', 'secondaryContacts']  # Add all list/dict columns\n",
    "for col in list_columns:\n",
    "    df[col] = df[col].apply(lambda x: json.dumps(x) if x is not None else None)\n",
    "\n",
    "numeric_columns = ['approvalCount', 'commentCount', 'taskCount', 'followerCount', 'tagCount', 'attachmentCount']\n",
    "for col in numeric_columns:\n",
    "    df[col] = df[col].fillna(0)\n",
    "\n",
    "text_columns = ['subject', 'statusType', 'channel', 'language', 'resolution', 'description', 'priority']\n",
    "for col in text_columns:\n",
    "    df[col] = df[col].astype(str).replace('None', None)\n",
    "\n",
    "\n",
    "# Now write to MySQL\n",
    "df.to_sql(name=TABLE_NAME, con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c3c71f2a-8f9b-4701-9e05-f045ca19ef98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 100 tickets starting from 1\n",
      "Fetched 100 tickets starting from 101\n",
      "Fetched 100 tickets starting from 201\n",
      "Fetched 100 tickets starting from 301\n",
      "Fetched 100 tickets starting from 401\n",
      "Fetched 100 tickets starting from 501\n",
      "Fetched 100 tickets starting from 601\n",
      "Fetched 3 tickets starting from 701\n",
      "Error: 204 - \n",
      "Total tickets fetched: 703\n",
      "Error fetching threads for ticket 980891000009854253: {\"errorCode\":\"TOO_MANY_REQUESTS\",\"message\":\"The maximum number of Concurrent API Calls that can be made has been exceeded.\"}\n",
      "\n",
      "Error fetching threads for ticket 980891000010028001: {\"errorCode\":\"TOO_MANY_REQUESTS\",\"message\":\"The maximum number of Concurrent API Calls that can be made has been exceeded.\"}\n",
      "\n",
      "Error fetching threads for ticket 980891000010042020: {\"errorCode\":\"TOO_MANY_REQUESTS\",\"message\":\"The maximum number of Concurrent API Calls that can be made has been exceeded.\"}\n",
      "\n",
      "Error fetching threads for ticket 980891000010043020: {\"errorCode\":\"TOO_MANY_REQUESTS\",\"message\":\"The maximum number of Concurrent API Calls that can be made has been exceeded.\"}\n",
      "\n",
      "Error fetching threads for ticket 980891000009993134: {\"errorCode\":\"TOO_MANY_REQUESTS\",\"message\":\"The maximum number of Concurrent API Calls that can be made has been exceeded.\"}\n",
      "\n",
      "Error fetching threads for ticket 980891000010176246: {\"errorCode\":\"TOO_MANY_REQUESTS\",\"message\":\"The maximum number of Concurrent API Calls that can be made has been exceeded.\"}\n",
      "\n",
      "Error fetching threads for ticket 980891000010238005: {\"errorCode\":\"TOO_MANY_REQUESTS\",\"message\":\"The maximum number of Concurrent API Calls that can be made has been exceeded.\"}\n",
      "\n",
      "Error fetching threads for ticket 980891000010180002: {\"errorCode\":\"TOO_MANY_REQUESTS\",\"message\":\"The maximum number of Concurrent API Calls that can be made has been exceeded.\"}\n",
      "\n",
      "Error fetching threads for ticket 980891000010246001: {\"errorCode\":\"TOO_MANY_REQUESTS\",\"message\":\"The maximum number of Concurrent API Calls that can be made has been exceeded.\"}\n",
      "\n",
      "Error fetching threads for ticket 980891000010190362: {\"errorCode\":\"TOO_MANY_REQUESTS\",\"message\":\"The maximum number of Concurrent API Calls that can be made has been exceeded.\"}\n",
      "\n",
      "Error fetching threads for ticket 980891000010204005: {\"errorCode\":\"TOO_MANY_REQUESTS\",\"message\":\"The maximum number of Concurrent API Calls that can be made has been exceeded.\"}\n",
      "\n",
      "Error fetching threads for ticket 980891000010130002: {\"errorCode\":\"TOO_MANY_REQUESTS\",\"message\":\"The maximum number of Concurrent API Calls that can be made has been exceeded.\"}\n",
      "\n",
      "Error fetching threads for ticket 980891000010190248: {\"errorCode\":\"TOO_MANY_REQUESTS\",\"message\":\"The maximum number of Concurrent API Calls that can be made has been exceeded.\"}\n",
      "\n",
      "Error fetching threads for ticket 980891000010105025: {\"errorCode\":\"TOO_MANY_REQUESTS\",\"message\":\"The maximum number of Concurrent API Calls that can be made has been exceeded.\"}\n",
      "\n",
      "Error fetching threads for ticket 980891000010131119: {\"errorCode\":\"TOO_MANY_REQUESTS\",\"message\":\"The maximum number of Concurrent API Calls that can be made has been exceeded.\"}\n",
      "\n",
      "Error fetching threads for ticket 980891000010190115: {\"errorCode\":\"TOO_MANY_REQUESTS\",\"message\":\"The maximum number of Concurrent API Calls that can be made has been exceeded.\"}\n",
      "\n",
      "Error fetching threads for ticket 980891000010175003: {\"errorCode\":\"TOO_MANY_REQUESTS\",\"message\":\"The maximum number of Concurrent API Calls that can be made has been exceeded.\"}\n",
      "\n",
      "Total threads fetched: 1702\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "# 🔹 Get a valid access token from your token logic\n",
    "ACCESS_TOKEN = get_access_token()  # Replace with your refresh token logic\n",
    "ORG_ID = \"852203610\"\n",
    "\n",
    "BASE_URL = \"https://desk.zoho.com/api/v1\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Zoho-oauthtoken {ACCESS_TOKEN}\",\n",
    "    \"orgId\": ORG_ID\n",
    "}\n",
    "\n",
    "limit = 100\n",
    "start = 1\n",
    "all_tickets = []\n",
    "\n",
    "# Step 1: Get all tickets with pagination\n",
    "while True:\n",
    "    params = {\"limit\": limit, \"from\": start}\n",
    "    resp = requests.get(f\"{BASE_URL}/tickets\", headers=headers, params=params)\n",
    "\n",
    "    if resp.status_code != 200:\n",
    "        print(f\"Error: {resp.status_code} - {resp.text}\")\n",
    "        break\n",
    "\n",
    "    tickets = resp.json().get(\"data\", [])\n",
    "    if not tickets:\n",
    "        break\n",
    "\n",
    "    all_tickets.extend(tickets)\n",
    "    print(f\"Fetched {len(tickets)} tickets starting from {start}\")\n",
    "\n",
    "    start += limit\n",
    "    time.sleep(0.2)  # Avoid hitting rate limits\n",
    "\n",
    "print(f\"Total tickets fetched: {len(all_tickets)}\")\n",
    "\n",
    "# Step 2: Function to fetch threads for a single ticket\n",
    "def fetch_ticket_threads(ticket):\n",
    "    ticket_id = ticket[\"id\"]\n",
    "    thread_url = f\"{BASE_URL}/tickets/{ticket_id}/threads\"\n",
    "    try:\n",
    "        resp = requests.get(thread_url, headers=headers)\n",
    "        if resp.status_code == 200:\n",
    "            threads = resp.json().get(\"data\", [])\n",
    "            for t in threads:\n",
    "                t[\"ticketId\"] = ticket_id\n",
    "            return threads\n",
    "        else:\n",
    "            print(f\"Error fetching threads for ticket {ticket_id}: {resp.text}\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"Exception fetching threads for ticket {ticket_id}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Step 3: Parallel fetching using ThreadPoolExecutor\n",
    "all_threads = []\n",
    "max_workers = 50  # Adjust based on API rate limits\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = [executor.submit(fetch_ticket_threads, ticket) for ticket in all_tickets]\n",
    "    for future in as_completed(futures):\n",
    "        threads = future.result()\n",
    "        if threads:\n",
    "            all_threads.extend(threads)\n",
    "\n",
    "print(f\"Total threads fetched: {len(all_threads)}\")\n",
    "\n",
    "# Step 4: Flatten JSON and save\n",
    "df_threads = pd.json_normalize(all_threads, sep=\".\")\n",
    "#df_threads.to_csv(\"zoho_ticket_threads.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "#df_threads.to_excel(\"zoho_ticket_threads.xlsx\", index=False)\n",
    "\n",
    "#print(\"✅ Ticket threads saved to CSV and Excel.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ef5a690d-dcb4-4629-81aa-993ecbfc9ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# MySQL connection details\n",
    "MYSQL_USER = 'integrationuser'\n",
    "MYSQL_PASSWORD = 'g1MBcJcn9bTkKgmmTzPGnWMPR499X76S66f52U9g'\n",
    "MYSQL_HOST = 'data-integration-aurora.cz4wwgmu4f45.us-east-2.rds.amazonaws.com'         # or your DB host\n",
    "MYSQL_PORT = 3306\n",
    "MYSQL_DB = 'supporttickets'\n",
    "TABLE_NAME = 'ticket_threads'\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine(f'mysql+pymysql://{MYSQL_USER}:{MYSQL_PASSWORD}@{MYSQL_HOST}:{MYSQL_PORT}/{MYSQL_DB}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3f511298-e8a7-4174-bec3-27e9a4909af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1702"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Convert lists to JSON strings\n",
    "df_threads['actions'] = df_threads['actions'].apply(lambda x: json.dumps(x) if isinstance(x, list) else x)\n",
    "df_threads['keyWords'] = df_threads['keyWords'].apply(lambda x: json.dumps(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Ensure all None values are properly handled\n",
    "df_threads = df_threads.fillna(\"\")\n",
    "\n",
    "# Convert list columns to JSON strings\n",
    "list_columns = ['aspects', 'actions', 'keyWords']\n",
    "for col in list_columns:\n",
    "    if col in df_threads.columns:\n",
    "        df_threads[col] = df_threads[col].apply(lambda x: json.dumps(x) if isinstance(x, (list, dict)) else x)\n",
    "\n",
    "\n",
    "from sqlalchemy.types import Integer, String, Text, JSON\n",
    "\n",
    "dtype_map = {\n",
    "    'actions': JSON,\n",
    "    'keyWords': JSON,\n",
    "    'summary': Text,\n",
    "    'fromEmailAddress': Text,\n",
    "    'id': String(50),\n",
    "    'ticketId': String(50)\n",
    "}\n",
    "\n",
    "df_threads.to_sql(name=TABLE_NAME, con=engine, if_exists='replace', index=False, dtype=dtype_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f4089404-9b4c-4dad-bbf8-7ff639ef70e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fetched 100 tickets starting from 1\n",
      "✅ Fetched 100 tickets starting from 101\n",
      "✅ Fetched 100 tickets starting from 201\n",
      "✅ Fetched 100 tickets starting from 301\n",
      "✅ Fetched 100 tickets starting from 401\n",
      "✅ Fetched 100 tickets starting from 501\n",
      "✅ Fetched 100 tickets starting from 601\n",
      "✅ Fetched 3 tickets starting from 701\n",
      "Error: 204 - \n",
      "🎯 Total tickets fetched: 703\n",
      "📜 Total history records fetched: 6619\n",
      "✅ Ticket history saved to CSV and Excel.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "# -----------------------------\n",
    "# Authentication details\n",
    "# -----------------------------\n",
    "ACCESS_TOKEN = get_access_token()  # Use your token refresh logic here\n",
    "ORG_ID = \"852203610\"\n",
    "\n",
    "BASE_URL = \"https://desk.zoho.com/api/v1\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Zoho-oauthtoken {ACCESS_TOKEN}\",\n",
    "    \"orgId\": ORG_ID\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Step 1: Fetch all tickets\n",
    "# -----------------------------\n",
    "limit = 100\n",
    "start = 1\n",
    "all_tickets = []\n",
    "\n",
    "while True:\n",
    "    params = {\"limit\": limit, \"from\": start}\n",
    "    resp = requests.get(f\"{BASE_URL}/tickets\", headers=headers, params=params)\n",
    "\n",
    "    if resp.status_code != 200:\n",
    "        print(f\"Error: {resp.status_code} - {resp.text}\")\n",
    "        break\n",
    "\n",
    "    tickets = resp.json().get(\"data\", [])\n",
    "    if not tickets:\n",
    "        break\n",
    "\n",
    "    all_tickets.extend(tickets)\n",
    "    print(f\"✅ Fetched {len(tickets)} tickets starting from {start}\")\n",
    "\n",
    "    start += limit\n",
    "    time.sleep(0.2)  # avoid rate limits\n",
    "\n",
    "print(f\"🎯 Total tickets fetched: {len(all_tickets)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2: Function to fetch ticket history\n",
    "# -----------------------------\n",
    "def fetch_ticket_history(ticket):\n",
    "    ticket_id = ticket[\"id\"]\n",
    "    history_url = f\"{BASE_URL}/tickets/{ticket_id}/history\"\n",
    "    try:\n",
    "        resp = requests.get(history_url, headers=headers)\n",
    "        if resp.status_code == 404:\n",
    "            return []  # No history\n",
    "        elif resp.status_code != 200:\n",
    "            print(f\"⚠️ Error fetching history for ticket {ticket_id}: {resp.text}\")\n",
    "            return []\n",
    "\n",
    "        history_list = resp.json()\n",
    "        for h in history_list:\n",
    "            h[\"ticketId\"] = ticket_id\n",
    "            h[\"ticketSubject\"] = ticket.get(\"subject\", \"\")\n",
    "            h[\"ticketStatus\"] = ticket.get(\"status\", \"\")\n",
    "            h[\"ticketPriority\"] = ticket.get(\"priority\", \"\")\n",
    "        return history_list\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Exception fetching history for ticket {ticket_id}: {e}\")\n",
    "        return []\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3: Parallel fetching with ThreadPoolExecutor\n",
    "# -----------------------------\n",
    "all_history = []\n",
    "max_workers = 10  # Adjust based on API limits\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = [executor.submit(fetch_ticket_history, t) for t in all_tickets]\n",
    "    for future in as_completed(futures):\n",
    "        history_records = future.result()\n",
    "        if history_records:\n",
    "            all_history.extend(history_records)\n",
    "\n",
    "print(f\"📜 Total history records fetched: {len(all_history)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 4: Save to CSV & Excel\n",
    "# -----------------------------\n",
    "if all_history:\n",
    "    df_history = pd.json_normalize(all_history, sep=\".\")\n",
    "    df_history.to_csv(\"zoho_ticket_history.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    df_history.to_excel(\"zoho_ticket_history.xlsx\", index=False)\n",
    "    print(\"✅ Ticket history saved to CSV and Excel.\")\n",
    "else:\n",
    "    print(\"⚠️ No history records found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b2079e91-41e3-4a5f-b894-7c38aec540bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# MySQL connection details\n",
    "MYSQL_USER = 'integrationuser'\n",
    "MYSQL_PASSWORD = 'g1MBcJcn9bTkKgmmTzPGnWMPR499X76S66f52U9g'\n",
    "MYSQL_HOST = 'data-integration-aurora.cz4wwgmu4f45.us-east-2.rds.amazonaws.com'         # or your DB host\n",
    "MYSQL_PORT = 3306\n",
    "MYSQL_DB = 'supporttickets'\n",
    "TABLE_NAME = 'tickets_history'\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine(f'mysql+pymysql://{MYSQL_USER}:{MYSQL_PASSWORD}@{MYSQL_HOST}:{MYSQL_PORT}/{MYSQL_DB}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c31b8762-15c7-4b74-be1e-729952c6e7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data uploaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sqlalchemy import create_engine, types\n",
    "# --- CLEAN YOUR DATAFRAME BEFORE UPLOAD ---\n",
    "def clean_dataframe(df):\n",
    "    for col in df.columns:\n",
    "        # Convert dicts/lists to JSON strings\n",
    "        df[col] = df[col].apply(\n",
    "            lambda x: json.dumps(x) if isinstance(x, (dict, list)) else x\n",
    "        )\n",
    "        # Replace NaN/None with None (SQL NULL)\n",
    "        df[col] = df[col].replace({np.nan: None})\n",
    "    return df\n",
    "\n",
    "# Example: your dataframe\n",
    "# df_history = pd.DataFrame(data)  # replace with your actual df\n",
    "df_history = clean_dataframe(df_history)\n",
    "\n",
    "# Explicit dtypes mapping for MySQL (important for JSON-like fields)\n",
    "dtype_map = {\n",
    "    \"recipients\": types.Text(),\n",
    "    \"name\": types.String(255),\n",
    "    \"eventTime\": types.String(50),\n",
    "    \"webLabel\": types.Text(),\n",
    "    \"ruleName\": types.Text(),\n",
    "    \"notificationType\": types.String(100),\n",
    "    \"ticketId\": types.String(50),\n",
    "    \"ticketSubject\": types.Text(),\n",
    "    \"ticketStatus\": types.String(50),\n",
    "    \"ticketPriority\": types.String(50),\n",
    "    \"actionType\": types.String(100),\n",
    "    \"agentId\": types.String(50),\n",
    "    \"changes\": types.Text(),\n",
    "    \"agentName\": types.String(255),\n",
    "    \"actionName\": types.String(255),\n",
    "    \"customerName\": types.String(255),\n",
    "    \"slaName\": types.String(255),\n",
    "    \"mergedTicketValues\": types.Text(),\n",
    "    \"mergedFromTicket\": types.Text(),\n",
    "    \"atMentions\": types.Text(),\n",
    "    \"tagName\": types.String(100),\n",
    "    \"rating\": types.String(50),\n",
    "    \"ratedAgent\": types.String(255),\n",
    "    \"comment\": types.Text(),\n",
    "}\n",
    "\n",
    "# --- UPLOAD SAFELY ---\n",
    "df_history.to_sql(\n",
    "    name=TABLE_NAME,\n",
    "    con=engine,\n",
    "    if_exists=\"replace\",   # or \"append\"\n",
    "    index=False,\n",
    "    dtype=dtype_map,\n",
    "    method=\"multi\",        # batch insert\n",
    "    chunksize=1000         # avoids packet size issues\n",
    ")\n",
    "print(\"✅ Data uploaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e95907a-4598-496c-aabc-0f0df27ea860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
